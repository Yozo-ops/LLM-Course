# 第一次迭代进行的工作
## 创造项目环境
为了高效管理项目依赖并避免环境冲突，本项目选用 Miniconda 作为环境管理工具（Miniconda 是 Anaconda 的轻量级版本，仅包含 conda 包管理器和 Python，占用资源更少）：
下载渠道：从Anaconda 官方网站获取对应操作系统（Windows）的 Miniconda 安装包；
安装流程：按照官方指引完成安装，勾选 “Add Miniconda3 to my PATH environment variable”（便于在 PowerShell 中直接调用 conda 指令）；
验证安装：在 PowerShell 中执行 conda --version，若输出 conda 版本号则说明安装成功。

## 数据集来源
本项目采用清华大学自然语言处理实验室发布的 THUCTC 中文文本分类数据集（官网：http://thuctc.thunlp.org/ ），选取其中体育领域子数据集作为 RAG 系统的知识库数据源。该数据集包含大量高质量的体育新闻、赛事分析、运动员介绍等文本，覆盖足球、篮球、乒乓球等多个体育项目，具备内容真实、领域特征鲜明的特点。

为适配 RAG 系统的检索需求，对原始体育数据进行了标准化预处理：
文本清洗：去除数据中的特殊符号、冗余空格、无效标签；
分词处理：使用 jieba 对中文文本进行分词，添加体育领域自定义词典（如 “世界杯”“常规赛”“MVP” 等）提升分词准确性；
文本分段：将长文本按语义切分为 200-500 字的短文本片段，避免检索时上下文冗余；
数据格式转换：将处理后的文本转换为 JSONL 格式，便于后续向量入库与检索调用。

## 模型
本项目选用阿里云通义千问发布的 Qwen2.5-4B 模型（轻量级、中文适配性优、本地部署门槛低），通过 Hugging Face 平台手动完成下载：
下载地址：Hugging Face Qwen2.5-4B 主页；
下载内容：完整下载模型文件夹（包含config.json、model.safetensors、tokenizer.json等核心文件）；
本地存放：将下载的模型文件统一存放至项目目录models/Qwen2.5-4B/下，便于代码调用。

## 项目仓库地址
https://github.com/Yozo-ops/LLM_Homework

## 优化方向
根据THUCTC 中文文本分类数据集，其中体育领域子数据集生成QA对，进行Lora微调

# 第二次迭代进行工作
## 微调专用 QA 数据集构建
为实现 Qwen2.5-4B 模型的体育领域适配，基于预处理后的 THUCTC 体育数据，调用 Qwen3-Max 模型生成专属 QA 对数据集：
生成逻辑：以 THUCTC 体育文本的核心信息为依据，引导 Qwen3-Max 生成贴合体育领域特征的 “问题 - 答案” 对，覆盖赛事规则、赛事结果、运动员成就等多类核心问题；
数据筛选：人工过滤无效、重复、表述不规范的 QA 对，最终得到千余条高质量体育领域 QA 对，保存为结构化文件，作为 Lora 微调的核心数据支撑。

## Lora 轻量化微调
针对通用大模型在体育领域回答精准度不足的问题，采用 Lora（Low-Rank Adaptation）轻量化微调技术对 Qwen2.5-4B 进行优化，核心实践如下：
微调核心优势：仅针对模型注意力层的少量参数进行训练，无需训练全量参数，大幅降低显存占用（普通 16G 显存 PC 即可完成），且微调后仅生成数十 MB 的 Lora 适配器文件，无需保存全量模型，兼顾效率与存储成本；
微调实现：编写Lora.py脚本作为核心微调入口，配置 Lora 关键参数（低秩矩阵的秩、缩放因子、目标微调模块等），加载预处理后的体育 QA 对数据集，设置合理的训练批次、学习率、训练轮数等训练参数；
执行与验证：在激活的 conda 环境中运行Lora.py完成微调，微调后的 Lora 适配器保存至指定目录；通过验证脚本加载 “原始 Qwen2.5-4B 模型 + Lora 适配器”，测试体育领域问题回答效果，确认微调后模型对体育领域专业问题的理解与回答能力显著提升。
